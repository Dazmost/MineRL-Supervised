{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b683329e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import minerl\n",
    "import tree_trajectory\n",
    "import network\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d32796d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#paths\n",
    "workspace_path= 'C:/Users/Halim/Downloads/minecraftRL/minecraft_bot_dev-master'\n",
    "data_path='C:/Users/Halim/Downloads/minecraftRL/MineRLenv'\n",
    "env_name = 'MineRLTreechop'\n",
    "gpu_use = True\n",
    "pretrained_model = None\n",
    "\n",
    "#if already trained model and/or gpu exists\n",
    "# parser = argparse.ArgumentParser(description='Minecraft Supervised Learning')\n",
    "# parser.add_argument('--pretrained_model', type=str, help='pretrained model name')\n",
    "# parser.add_argument('--gpu_use', type=bool, default=False, help='use gpu')\n",
    "# arguments = parser.parse_args()\n",
    "\n",
    "#if gpu exists\n",
    "if gpu_use == True:\n",
    "    gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "    tf.config.experimental.set_virtual_device_configuration(gpus[0],\n",
    "                [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=4000)])\n",
    "else:\n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "\n",
    "#location for model summary\n",
    "writer = tf.summary.create_file_writer(workspace_path + \"/tree_tensorboard\")\n",
    "\n",
    "    \n",
    "num_actions = 43\n",
    "num_hidden_units = 512\n",
    "\n",
    "#https://www.tensorflow.org/api_docs/python/tf/keras/losses/CategoricalCrossentropy\n",
    "cce_loss = tf.keras.losses.CategoricalCrossentropy()\n",
    "cce_loss_logits = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "optimizer = tf.keras.optimizers.Adam(0.0001)#basically gradient descent\n",
    "#https://www.geeksforgeeks.org/intuition-of-adam-optimizer/"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c9830526",
   "metadata": {},
   "source": [
    "https://stackoverflow.com/questions/41455101/what-is-the-meaning-of-the-word-logits-in-tensorflow\n",
    "\n",
    "from_logits\n",
    "\n",
    "Whether y_pred is expected to be a logits tensor. By default, we assume that y_pred encodes a probability distribution. \n",
    "\n",
    "For Tensorflow: It's a name that it is thought to imply that this Tensor is the quantity that is being mapped to probabilities by the Softmax. \n",
    "\n",
    "Personal understanding, in TensorFlow domain, logits are the values to be used as input to softmax. I came to this understanding based on this tensorflow tutorial.\n",
    "\n",
    "Greate!Can you make a simple example? Is this right?[1, 0.5, 0.5] through normalization become [0.5, 0.25, 0.25] and then soft max become[0,] if one hot [1, 0, 0]? or just out put [1, 0, 0] cause the output should be a vector?\n",
    "\n",
    "In TensorFlow, logit refers to the unscaled output of a layer, which can be input into any activation function, not just Softmax. This is illustrated by tf.nn.sigmoid_cross_entropy_with_logits. The with_logits suffix simply denotes that unscaled logit output should be passed, not the prediction output from the final layer activation function that is typically used by error functions such as tf.keras.losses.MSE or tf.keras.losses.CategoricalCrossentropy\n",
    "\n",
    "Example: the last layer of a NN returns a tensor k = [1,2,3,4,1,2,3] of logits, which classifies an input as belonging to each of 7 possible categories. Note that the fourth logit is the biggest, i.e., the fourth category is the most probable, and that it is four times the first one. k is fed to a softmax function that returns the probabilities [0.02,0.06, 0.18,0.48,0.02,0.06,0.18] that the input belongs to each category (softmax is a normalized exponential function). Note that the fourth probability is 24 times the first one (due to the exponential term in softmax) and that all sum 1."
   ]
  },
  {
   "cell_type": "raw",
   "id": "78d41a20",
   "metadata": {},
   "source": [
    "Yes, logit as a mathematical function in statistics, but the logit used in context of neural networks is different. Statistical logit doesn't even make any sense here.\n",
    "\n",
    "I couldn't find a formal definition anywhere, but logit basically means:\n",
    "\n",
    "The raw predictions which come out of the last layer of the neural network.\n",
    "1. This is the very tensor on which you apply the argmax function to get the predicted class.\n",
    "2. This is the very tensor which you feed into the softmax function to get the probabilities for the predicted classes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "395056ac",
   "metadata": {},
   "source": [
    "https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a4919e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def supervised_replay(replay_obs_list, replay_act_list, memory_state, carry_state):\n",
    "    replay_obs_array = tf.concat(replay_obs_list, 0)\n",
    "    replay_act_array = tf.concat(replay_act_list, 0)\n",
    "    replay_memory_state_array = tf.concat(memory_state, 0)\n",
    "    replay_carry_state_array = tf.concat(carry_state, 0)\n",
    "\n",
    "    memory_state = replay_memory_state_array\n",
    "    carry_state = replay_carry_state_array\n",
    "\n",
    "    batch_size = replay_obs_array.shape[0]\n",
    "    tf.print(\"batch_size: \", batch_size)\n",
    "        \n",
    "    with tf.GradientTape() as tape:\n",
    "        act_probs = tf.TensorArray(dtype=tf.float32, size=0, dynamic_size=True)\n",
    "        for i in tf.range(0, batch_size):\n",
    "            prediction = model(tf.expand_dims(replay_obs_array[i,:,:,:], 0), memory_state, carry_state, training=True)\n",
    "            act_pi = prediction[0]\n",
    "            memory_state = prediction[2]\n",
    "            carry_state = prediction[3]\n",
    "            \n",
    "            act_probs = act_probs.write(i, act_pi[0])\n",
    "\n",
    "        act_probs = act_probs.stack()\n",
    "\n",
    "        tf.print(\"replay_act_array: \", replay_act_array)\n",
    "        tf.print(\"tf.argmax(act_probs, 1): \", tf.argmax(act_probs, 1))\n",
    "\n",
    "        replay_act_array_onehot = tf.one_hot(replay_act_array, num_actions)\n",
    "        replay_act_array_onehot = tf.reshape(replay_act_array_onehot, (batch_size, num_actions))\n",
    "        act_loss = cce_loss_logits(replay_act_array_onehot, act_probs)\n",
    "\n",
    "        #tf.print(\"act_loss: \", act_loss)\n",
    "        regularization_loss = tf.reduce_sum(model.losses)\n",
    "        total_loss = act_loss + 1e-5 * regularization_loss #the derivative of this function is calculated with model.trainable_variables (weights) as input\n",
    "        \n",
    "        #tf.print(\"total_loss: \", total_loss)\n",
    "        #tf.print(\"\")\n",
    "    \n",
    "    #taking the derivative of the cost/loss function and filling in the parameter weights as input to the loss function\n",
    "    grads = tape.gradient(total_loss, model.trainable_variables)\n",
    "    #using the optimizer to perform gradient descent to update the weights\n",
    "    optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "\n",
    "    return total_loss, memory_state, carry_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "52483f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def supervised_train(dataset, training_episode):\n",
    "        for batch in dataset:\n",
    "            episode_size = batch[0].shape[1] #number of images in a video/trajectory (e.g. 1645 episodes/images)\n",
    "            print(\"episode_size: \", episode_size) #only 1 batch which has all the episodes/images in a video\n",
    "        \n",
    "            replay_obs_list = batch[0][0] #image \n",
    "                                            #tf.Tensor([1645   64   64    3], shape=(4,), dtype=int32)\n",
    "            replay_act_list = batch[1][0] #hot-encoded action 0 to 42 \n",
    "                                            #tf.Tensor([1645    1], shape=(2,), dtype=int32)\n",
    "        \n",
    "            memory_state = np.zeros([1,128], dtype=np.float32) #1 by 128 matrix of zeros\n",
    "            carry_state =  np.zeros([1,128], dtype=np.float32) # 1 by 128 matrix of zeros [[0 0 0...0 0 0]]\n",
    "            step_length = 32 #images/episodes per step in training before back propagation?\n",
    "            total_loss = 0\n",
    "            for episode_index in range(0, episode_size, step_length): #steps of 32 episodes/images\n",
    "                obs = replay_obs_list[episode_index:episode_index+step_length,:,:,:]\n",
    "                act = replay_act_list[episode_index:episode_index+step_length,:]\n",
    "                \n",
    "                #print(\"len(obs): \", len(obs))\n",
    "                if len(obs) != step_length:\n",
    "                    break\n",
    "                \n",
    "                total_loss, next_memory_state, next_carry_state = supervised_replay(obs, act, memory_state, carry_state)\n",
    "                memory_state = next_memory_state\n",
    "                carry_state = next_carry_state\n",
    "            \n",
    "                print(\"total_loss: \", total_loss)\n",
    "                print(\"\")\n",
    "                \n",
    "            with writer.as_default():\n",
    "                tf.summary.scalar(\"total_loss\", total_loss, step=training_episode)\n",
    "                writer.flush()\n",
    "\n",
    "            if training_episode % 1 == 0:#100\n",
    "                model.save_weights(workspace_path + '/model/tree_supervised_model_' + str(training_episode))\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "364587d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MineRL Setup\n",
    "env_name = 'MineRLTreechop'\n",
    "# writer = tf.summary.create_file_writer(workspace_path + \"/tree_tensorboard\")\n",
    "tree_data = minerl.data.make('MineRLTreechop-v0', data_dir=data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "087754e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################\n",
    "class TreeTrajectoryDataset(tf.data.Dataset):\n",
    "    def _generator(num_trajectorys):\n",
    "        while True:\n",
    "            trajectory_names = tree_data.get_trajectory_names()\n",
    "            #print(\"len(trajectory_names): \", len(trajectory_names))\n",
    "                \n",
    "            #https://minerl.io/docs/api/data.html\n",
    "            trajectory_name = random.choice(trajectory_names)\n",
    "            print(\"trajectory_name: \", trajectory_name)\n",
    "                \n",
    "            trajectory = tree_data.load_data(trajectory_name, skip_interval=0, include_metadata=False)\n",
    "            #print(\"trajectory: \", trajectory)\n",
    "                \n",
    "            noop_action_num = 0\n",
    "                \n",
    "            all_actions = []\n",
    "            all_obs = []\n",
    "            for dataset_observation, dataset_action, reward, next_state, done in trajectory:  \n",
    "                #print(\"reward: \", reward)\n",
    "                    \n",
    "                #state_pov = dataset_observation['pov']\n",
    "                #observation = np.concatenate((dataset_observation['pov'] / 255.0, inventory_channel), axis=2)\n",
    "                # OrderedDict([('pov', array([[[ 0,  0,  0],\n",
    "                #         [ 0,  0,  2],\n",
    "                #         [ 0,  2,  0],\n",
    "                #         ...,\n",
    "                #         [30, 57, 16],\n",
    "                #         [ 0,  2,  0],\n",
    "                #         [ 0,  2,  0]]], dtype=uint8))])\n",
    "                observation = dataset_observation['pov'] / 255.0\n",
    "\n",
    "                #OrderedDict([('attack', 1), ('back', 0), ('camera', array([0., 0.], dtype=float32)), ('forward', 0), ('jump', 0), ('left', 0), ('right', 0), ('sneak', 0), ('sprint', 0)])\n",
    "                action_camera_0 = dataset_action['camera'][0]\n",
    "                action_camera_1 = dataset_action['camera'][1]\n",
    "                action_attack = dataset_action['attack']\n",
    "                action_forward = dataset_action['forward']\n",
    "                action_jump = dataset_action['jump']\n",
    "                action_back = dataset_action['back']\n",
    "                action_left = dataset_action['left']\n",
    "                action_right = dataset_action['right']\n",
    "                action_sneak = dataset_action['sneak']\n",
    "\n",
    "                camera_threshols = (abs(action_camera_0) + abs(action_camera_1)) / 2.0\n",
    "                if (camera_threshols > 2.5):\n",
    "                    if ( (action_camera_1 < 0) & ( abs(action_camera_0) < abs(action_camera_1) ) ):\n",
    "                        if (action_attack == 1):\n",
    "                            action_index = 0\n",
    "                        elif (action_forward == 1):\n",
    "                            action_index = 1\n",
    "                        elif (action_left == 1):\n",
    "                            action_index = 2\n",
    "                        elif (action_right == 1):\n",
    "                            action_index = 3\n",
    "                        elif (action_back == 1):\n",
    "                            action_index = 4\n",
    "                        elif (action_jump == 1):\n",
    "                            action_index = 5\n",
    "                        else:\n",
    "                            action_index = 6\n",
    "                    elif ( (action_camera_1 > 0) & ( abs(action_camera_0) < abs(action_camera_1) ) ):\n",
    "                        if (action_attack == 1):\n",
    "                            action_index = 7\n",
    "                        elif (action_forward == 1):\n",
    "                            action_index = 8\n",
    "                        elif (action_left == 1):\n",
    "                            action_index = 9\n",
    "                        elif (action_right == 1):\n",
    "                            action_index = 10\n",
    "                        elif (action_back == 1):\n",
    "                            action_index = 11\n",
    "                        elif (action_jump == 1):\n",
    "                            action_index = 12\n",
    "                        else:\n",
    "                            action_index = 13\n",
    "                    elif ( (action_camera_0 < 0) & ( abs(action_camera_0) > abs(action_camera_1) ) ):\n",
    "                        if (action_attack == 1):\n",
    "                            action_index = 14\n",
    "                        elif (action_forward == 1):\n",
    "                            action_index = 15\n",
    "                        elif (action_left == 1):\n",
    "                            action_index = 16\n",
    "                        elif (action_right == 1):\n",
    "                            action_index = 17\n",
    "                        elif (action_back == 1):\n",
    "                            action_index = 18\n",
    "                        elif (action_jump == 1):\n",
    "                            action_index = 19\n",
    "                        else:\n",
    "                            action_index = 20\n",
    "                    elif ( (action_camera_0 > 0) & ( abs(action_camera_0) > abs(action_camera_1) ) ):\n",
    "                        if (action_attack == 1):\n",
    "                            action_index = 21\n",
    "                        elif (action_forward == 1):\n",
    "                            action_index = 22\n",
    "                        elif (action_left == 1):\n",
    "                            action_index = 23\n",
    "                        elif (action_right == 1):\n",
    "                            action_index = 24\n",
    "                        elif (action_back == 1):\n",
    "                            action_index = 25\n",
    "                        elif (action_jump == 1):\n",
    "                            action_index = 26\n",
    "                        else:\n",
    "                            action_index = 27\n",
    "\n",
    "                elif (action_forward == 1):\n",
    "                    if (action_attack == 1):\n",
    "                        action_index = 28\n",
    "                    elif (action_jump == 1):\n",
    "                        action_index = 29\n",
    "                    else:\n",
    "                        action_index = 30\n",
    "                elif (action_jump == 1):\n",
    "                    if (action_attack == 1):\n",
    "                        action_index = 31\n",
    "                    else:\n",
    "                        action_index = 32\n",
    "                elif (action_back == 1):\n",
    "                    if (action_attack == 1):\n",
    "                        action_index = 33\n",
    "                    else:\n",
    "                        action_index = 34\n",
    "                elif (action_left == 1):\n",
    "                    if (action_attack == 1):\n",
    "                        action_index = 35\n",
    "                    else:\n",
    "                        action_index = 36\n",
    "                elif (action_right == 1):\n",
    "                    if (action_attack == 1):\n",
    "                        action_index = 37\n",
    "                    else:\n",
    "                        action_index = 38\n",
    "                elif (action_sneak == 1):\n",
    "                    if (action_attack == 1):\n",
    "                        action_index = 39\n",
    "                    else:\n",
    "                        action_index = 40\n",
    "                elif (action_attack == 1):\n",
    "                    action_index = 41\n",
    "                else:\n",
    "                    action_index = 42\n",
    "\n",
    "                if (dataset_action['attack'] == 0 and dataset_action['back'] == 0 and dataset_action['camera'][0] == 0.0 and \n",
    "                    dataset_action['camera'][1] == 0.0 and dataset_action['forward'] == 0 and dataset_action['jump'] == 0 and \n",
    "                    dataset_action['left'] == 0 and dataset_action['right'] == 0 and dataset_action['sneak'] == 0):\n",
    "                    #print(\"continue: \")\n",
    "                    continue\n",
    "\n",
    "                if action_index == 41:\n",
    "                    #print(\"camera_threshols: \", camera_threshols)\n",
    "                    #print(\"dataset_action: \", dataset_action)\n",
    "                    noop_action_num += 1\n",
    "                        \n",
    "                #print(\"observation.shape: \", observation.shap\n",
    "                #print(\"action_index: \", action_index)\n",
    "                #print(\"done: \", done)\n",
    "\n",
    "                all_obs.append(observation)\n",
    "                all_actions.append(np.array([action_index]))\n",
    "\n",
    "            print(\"len(all_obs): \", len(all_obs))\n",
    "            print(\"noop_action_num: \", noop_action_num)\n",
    "            print(\"\")\n",
    "            yield (all_obs, all_actions)\n",
    "\n",
    "            break\n",
    "    \n",
    "    def __new__(cls, num_trajectorys=3):\n",
    "        return tf.data.Dataset.from_generator(\n",
    "            cls._generator,\n",
    "            output_types=(tf.dtypes.float32, tf.dtypes.int32),\n",
    "            args=(num_trajectorys,)\n",
    "        )\n",
    "\n",
    "\n",
    "#################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "267ccaee",
   "metadata": {},
   "source": [
    "https://www.tensorflow.org/guide/data_performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2aed6912",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = tf.data.Dataset.range(1).interleave(TreeTrajectoryDataset, \n",
    "# num_parallel_calls=tf.data.experimental.AUTOTUNE).batch(1).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "dataset = tf.data.Dataset.range(1).interleave(TreeTrajectoryDataset, \n",
    "num_parallel_calls=tf.data.AUTOTUNE).batch(1).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "# num_actions = 43\n",
    "# num_hidden_units = 512\n",
    "\n",
    "#model = tf.keras.models.load_model('MineRL_SL_Model')\n",
    "model = network.ActorCritic(num_actions, num_hidden_units)\n",
    "\n",
    "if pretrained_model != None:\n",
    "    print(\"Load Pretrained Model\")\n",
    "    model.load_weights(\"model/\" + arguments.pretrained_model)\n",
    "\n",
    "        \n",
    "# cce_loss = tf.keras.losses.CategoricalCrossentropy()\n",
    "# cce_loss_logits = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "# optimizer = tf.keras.optimizers.Adam(0.0001)\n",
    "\n",
    "# for training_episode in range(0, 101): #2000000\n",
    "#     supervised_train(dataset, training_episode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "238eda59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if __name__ == '__main__':\n",
    "#     main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5d15ec48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PrefetchDataset element_spec=(TensorSpec(shape=<unknown>, dtype=tf.float32, name=None), TensorSpec(shape=<unknown>, dtype=tf.int32, name=None))>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "8a550092",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trajectory_name:  v3_content_squash_angel-3_16074-17640\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1528/1528 [00:00<00:00, 16969.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(all_obs):  1521\n",
      "noop_action_num:  986\n",
      "\n",
      "episode_size:  1521\n",
      "1521\n",
      "tf.Tensor(\n",
      "[[41]\n",
      " [41]\n",
      " [41]\n",
      " ...\n",
      " [41]\n",
      " [41]\n",
      " [41]], shape=(1521, 1), dtype=int32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "count=0\n",
    "for batch in dataset: #only 1 batch which has all the episodes/images in a video\n",
    "    episode_size = batch[0].shape[1]\n",
    "    count=count+1\n",
    "    print(\"episode_size: \", episode_size)\n",
    "    replay_obs_list = batch[0][0]\n",
    "    print(len(replay_obs_list))\n",
    "    replay_act_list = batch[1][0]\n",
    "    print(replay_act_list)\n",
    "    # episode_size = batch[0].shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "5fa89a2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ad5c4556",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_test = tf.data.Dataset.range(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4fba1bfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<RangeDataset element_spec=TensorSpec(shape=(), dtype=tf.int64, name=None)>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "88bb37f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n"
     ]
    }
   ],
   "source": [
    "dataset_test2 = tf.data.Dataset.range(42)\n",
    "print(dataset_test2.cardinality().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fb4d292e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.data.experimental.AUTOTUNE"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6bca1a5b",
   "metadata": {},
   "source": [
    "https://www.tensorflow.org/api_docs/python/tf/data/Dataset#interleave\n",
    "interleave(\n",
    "    map_func,\n",
    "    cycle_length=None,\n",
    "    block_length=None,\n",
    "    num_parallel_calls=None,\n",
    "    deterministic=None,\n",
    "    name=None\n",
    ")\n",
    "\n",
    "Maps map_func across this dataset, and interleaves the results.\n",
    "\n",
    "The type signature is:\n",
    "def interleave(\n",
    "  self: Dataset[T],\n",
    "  map_func: Callable[[T], Dataset[S]]\n",
    ") -> Dataset[S]\n",
    "\n",
    "For example, you can use Dataset.interleave() to process many input files concurrently:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd87aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess 4 files concurrently, and interleave blocks of 16 records\n",
    "# from each file.\n",
    "filenames = [\"/var/data/file1.txt\", \"/var/data/file2.txt\",\n",
    "             \"/var/data/file3.txt\", \"/var/data/file4.txt\"]\n",
    "dataset = tf.data.Dataset.from_tensor_slices(filenames)\n",
    "def parse_fn(filename):\n",
    "  return tf.data.Dataset.range(10)\n",
    "dataset = dataset.interleave(lambda x:\n",
    "    tf.data.TextLineDataset(x).map(parse_fn, num_parallel_calls=1),\n",
    "    cycle_length=4, block_length=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "922619c8",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "in user code:\n\n    File \"C:\\Users\\Halim\\AppData\\Local\\Temp\\ipykernel_9684\\2754542216.py\", line 4, in None  *\n        lambda x: Dataset.from_tensors(x).repeat(6)\n\n    NameError: name 'Dataset' is not defined\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [44]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m dataset \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataset\u001b[38;5;241m.\u001b[39mrange(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m6\u001b[39m)  \u001b[38;5;66;03m# ==> [ 1, 2, 3, 4, 5 ]\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# NOTE: New lines indicate \"block\" boundaries.\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterleave\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mDataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_tensors\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrepeat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m6\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcycle_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mblock_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mlist\u001b[39m(dataset\u001b[38;5;241m.\u001b[39mas_numpy_iterator())\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:2212\u001b[0m, in \u001b[0;36mDatasetV2.interleave\u001b[1;34m(self, map_func, cycle_length, block_length, num_parallel_calls, deterministic, name)\u001b[0m\n\u001b[0;32m   2209\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m deterministic \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m DEBUG_MODE:\n\u001b[0;32m   2210\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe `deterministic` argument has no effect unless the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2211\u001b[0m                   \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`num_parallel_calls` argument is specified.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 2212\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mInterleaveDataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2213\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcycle_length\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mblock_length\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2214\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2215\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m ParallelInterleaveDataset(\n\u001b[0;32m   2216\u001b[0m       \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   2217\u001b[0m       map_func,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2221\u001b[0m       deterministic\u001b[38;5;241m=\u001b[39mdeterministic,\n\u001b[0;32m   2222\u001b[0m       name\u001b[38;5;241m=\u001b[39mname)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:5365\u001b[0m, in \u001b[0;36mInterleaveDataset.__init__\u001b[1;34m(self, input_dataset, map_func, cycle_length, block_length, name)\u001b[0m\n\u001b[0;32m   5362\u001b[0m \u001b[38;5;124;03m\"\"\"See `Dataset.interleave()` for details.\"\"\"\u001b[39;00m\n\u001b[0;32m   5364\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_input_dataset \u001b[38;5;241m=\u001b[39m input_dataset\n\u001b[1;32m-> 5365\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_map_func \u001b[38;5;241m=\u001b[39m \u001b[43mstructured_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mStructuredFunctionWrapper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   5366\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmap_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_transformation_name\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_dataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   5367\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_map_func\u001b[38;5;241m.\u001b[39moutput_structure, DatasetSpec):\n\u001b[0;32m   5368\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m   5369\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe `map_func` argument must return a `Dataset` object. Got \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   5370\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_get_type(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_map_func\u001b[38;5;241m.\u001b[39moutput_structure)\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py:271\u001b[0m, in \u001b[0;36mStructuredFunctionWrapper.__init__\u001b[1;34m(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs)\u001b[0m\n\u001b[0;32m    264\u001b[0m       warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    265\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEven though the `tf.config.experimental_run_functions_eagerly` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    266\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moption is set, this option does not apply to tf.data functions. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    267\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTo force eager execution of tf.data functions, please use \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    268\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`tf.data.experimental.enable_debug_mode()`.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    269\u001b[0m     fn_factory \u001b[38;5;241m=\u001b[39m trace_tf_function(defun_kwargs)\n\u001b[1;32m--> 271\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function \u001b[38;5;241m=\u001b[39m \u001b[43mfn_factory\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    272\u001b[0m \u001b[38;5;66;03m# There is no graph to add in eager mode.\u001b[39;00m\n\u001b[0;32m    273\u001b[0m add_to_graph \u001b[38;5;241m&\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecuting_eagerly()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2567\u001b[0m, in \u001b[0;36mFunction.get_concrete_function\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2558\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_concrete_function\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m   2559\u001b[0m   \u001b[38;5;124;03m\"\"\"Returns a `ConcreteFunction` specialized to inputs and execution context.\u001b[39;00m\n\u001b[0;32m   2560\u001b[0m \n\u001b[0;32m   2561\u001b[0m \u001b[38;5;124;03m  Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2565\u001b[0m \u001b[38;5;124;03m       or `tf.Tensor` or `tf.TensorSpec`.\u001b[39;00m\n\u001b[0;32m   2566\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m-> 2567\u001b[0m   graph_function \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_concrete_function_garbage_collected(\n\u001b[0;32m   2568\u001b[0m       \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   2569\u001b[0m   graph_function\u001b[38;5;241m.\u001b[39m_garbage_collector\u001b[38;5;241m.\u001b[39mrelease()  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m   2570\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m graph_function\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2533\u001b[0m, in \u001b[0;36mFunction._get_concrete_function_garbage_collected\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2531\u001b[0m   args, kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   2532\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m-> 2533\u001b[0m   graph_function, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_define_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2534\u001b[0m   seen_names \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n\u001b[0;32m   2535\u001b[0m   captured \u001b[38;5;241m=\u001b[39m object_identity\u001b[38;5;241m.\u001b[39mObjectIdentitySet(\n\u001b[0;32m   2536\u001b[0m       graph_function\u001b[38;5;241m.\u001b[39mgraph\u001b[38;5;241m.\u001b[39minternal_captures)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2711\u001b[0m, in \u001b[0;36mFunction._maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   2708\u001b[0m   cache_key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function_cache\u001b[38;5;241m.\u001b[39mgeneralize(cache_key)\n\u001b[0;32m   2709\u001b[0m   (args, kwargs) \u001b[38;5;241m=\u001b[39m cache_key\u001b[38;5;241m.\u001b[39m_placeholder_value()  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m-> 2711\u001b[0m graph_function \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_graph_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2712\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function_cache\u001b[38;5;241m.\u001b[39madd(cache_key, cache_key_deletion_observer,\n\u001b[0;32m   2713\u001b[0m                          graph_function)\n\u001b[0;32m   2715\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m graph_function, filtered_flat_args\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2627\u001b[0m, in \u001b[0;36mFunction._create_graph_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   2622\u001b[0m missing_arg_names \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m   2623\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (arg, i) \u001b[38;5;28;01mfor\u001b[39;00m i, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(missing_arg_names)\n\u001b[0;32m   2624\u001b[0m ]\n\u001b[0;32m   2625\u001b[0m arg_names \u001b[38;5;241m=\u001b[39m base_arg_names \u001b[38;5;241m+\u001b[39m missing_arg_names\n\u001b[0;32m   2626\u001b[0m graph_function \u001b[38;5;241m=\u001b[39m ConcreteFunction(\n\u001b[1;32m-> 2627\u001b[0m     \u001b[43mfunc_graph_module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc_graph_from_py_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2628\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2629\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_python_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2630\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2631\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2632\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput_signature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2633\u001b[0m \u001b[43m        \u001b[49m\u001b[43mautograph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_autograph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2634\u001b[0m \u001b[43m        \u001b[49m\u001b[43mautograph_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_autograph_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2635\u001b[0m \u001b[43m        \u001b[49m\u001b[43marg_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43marg_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2636\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapture_by_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_capture_by_value\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[0;32m   2637\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function_attributes,\n\u001b[0;32m   2638\u001b[0m     spec\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_spec,\n\u001b[0;32m   2639\u001b[0m     \u001b[38;5;66;03m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[39;00m\n\u001b[0;32m   2640\u001b[0m     \u001b[38;5;66;03m# scope. This is not the default behavior since it gets used in some\u001b[39;00m\n\u001b[0;32m   2641\u001b[0m     \u001b[38;5;66;03m# places (like Keras) where the FuncGraph lives longer than the\u001b[39;00m\n\u001b[0;32m   2642\u001b[0m     \u001b[38;5;66;03m# ConcreteFunction.\u001b[39;00m\n\u001b[0;32m   2643\u001b[0m     shared_func_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m   2644\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m graph_function\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:1141\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, acd_record_initial_resource_uses)\u001b[0m\n\u001b[0;32m   1138\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1139\u001b[0m   _, original_func \u001b[38;5;241m=\u001b[39m tf_decorator\u001b[38;5;241m.\u001b[39munwrap(python_func)\n\u001b[1;32m-> 1141\u001b[0m func_outputs \u001b[38;5;241m=\u001b[39m python_func(\u001b[38;5;241m*\u001b[39mfunc_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfunc_kwargs)\n\u001b[0;32m   1143\u001b[0m \u001b[38;5;66;03m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[39;00m\n\u001b[0;32m   1144\u001b[0m \u001b[38;5;66;03m# TensorArrays and `None`s.\u001b[39;00m\n\u001b[0;32m   1145\u001b[0m func_outputs \u001b[38;5;241m=\u001b[39m nest\u001b[38;5;241m.\u001b[39mmap_structure(\n\u001b[0;32m   1146\u001b[0m     convert, func_outputs, expand_composites\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py:248\u001b[0m, in \u001b[0;36mStructuredFunctionWrapper.__init__.<locals>.trace_tf_function.<locals>.wrapped_fn\u001b[1;34m(*args)\u001b[0m\n\u001b[0;32m    242\u001b[0m \u001b[38;5;129m@eager_function\u001b[39m\u001b[38;5;241m.\u001b[39mdefun_with_attributes(\n\u001b[0;32m    243\u001b[0m     input_signature\u001b[38;5;241m=\u001b[39mstructure\u001b[38;5;241m.\u001b[39mget_flat_tensor_specs(\n\u001b[0;32m    244\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_input_structure),\n\u001b[0;32m    245\u001b[0m     autograph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    246\u001b[0m     attributes\u001b[38;5;241m=\u001b[39mdefun_kwargs)\n\u001b[0;32m    247\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped_fn\u001b[39m(\u001b[38;5;241m*\u001b[39margs):  \u001b[38;5;66;03m# pylint: disable=missing-docstring\u001b[39;00m\n\u001b[1;32m--> 248\u001b[0m   ret \u001b[38;5;241m=\u001b[39m \u001b[43mwrapper_helper\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    249\u001b[0m   ret \u001b[38;5;241m=\u001b[39m structure\u001b[38;5;241m.\u001b[39mto_tensor_list(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_structure, ret)\n\u001b[0;32m    250\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m [ops\u001b[38;5;241m.\u001b[39mconvert_to_tensor(t) \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m ret]\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py:177\u001b[0m, in \u001b[0;36mStructuredFunctionWrapper.__init__.<locals>.wrapper_helper\u001b[1;34m(*args)\u001b[0m\n\u001b[0;32m    175\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _should_unpack(nested_args):\n\u001b[0;32m    176\u001b[0m   nested_args \u001b[38;5;241m=\u001b[39m (nested_args,)\n\u001b[1;32m--> 177\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[43mautograph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtf_convert\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mag_ctx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mnested_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    178\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _should_pack(ret):\n\u001b[0;32m    179\u001b[0m   ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(ret)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:692\u001b[0m, in \u001b[0;36mconvert.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    690\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[0;32m    691\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mag_error_metadata\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m--> 692\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mag_error_metadata\u001b[38;5;241m.\u001b[39mto_exception(e)\n\u001b[0;32m    693\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    694\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:689\u001b[0m, in \u001b[0;36mconvert.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    687\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    688\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m conversion_ctx:\n\u001b[1;32m--> 689\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    690\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[0;32m    691\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mag_error_metadata\u001b[39m\u001b[38;5;124m'\u001b[39m):\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:439\u001b[0m, in \u001b[0;36mconverted_call\u001b[1;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[0;32m    437\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    438\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 439\u001b[0m     result \u001b[38;5;241m=\u001b[39m converted_f(\u001b[38;5;241m*\u001b[39meffective_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    440\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    441\u001b[0m     result \u001b[38;5;241m=\u001b[39m converted_f(\u001b[38;5;241m*\u001b[39meffective_args)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_fileo8690ggd.py:5\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner_factory\u001b[39m(ag__):\n\u001b[1;32m----> 5\u001b[0m     tf__lam \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwith_function_scope\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mlscope\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_tensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlscope\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrepeat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m6\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlscope\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlscope\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSTD\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tf__lam\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\autograph\\core\\function_wrappers.py:113\u001b[0m, in \u001b[0;36mwith_function_scope\u001b[1;34m(thunk, scope_name, options)\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;124;03m\"\"\"Inline version of the FunctionScope context manager.\"\"\"\u001b[39;00m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m FunctionScope(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlambda_\u001b[39m\u001b[38;5;124m'\u001b[39m, scope_name, options) \u001b[38;5;28;01mas\u001b[39;00m scope:\n\u001b[1;32m--> 113\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mthunk\u001b[49m\u001b[43m(\u001b[49m\u001b[43mscope\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_fileo8690ggd.py:5\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.<lambda>\u001b[1;34m(lscope)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner_factory\u001b[39m(ag__):\n\u001b[1;32m----> 5\u001b[0m     tf__lam \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m x: ag__\u001b[38;5;241m.\u001b[39mwith_function_scope(\u001b[38;5;28;01mlambda\u001b[39;00m lscope: ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mconverted_call(\u001b[43mDataset\u001b[49m\u001b[38;5;241m.\u001b[39mfrom_tensors, (x,), \u001b[38;5;28;01mNone\u001b[39;00m, lscope)\u001b[38;5;241m.\u001b[39mrepeat, (\u001b[38;5;241m6\u001b[39m,), \u001b[38;5;28;01mNone\u001b[39;00m, lscope), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlscope\u001b[39m\u001b[38;5;124m'\u001b[39m, ag__\u001b[38;5;241m.\u001b[39mSTD)\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tf__lam\n",
      "\u001b[1;31mNameError\u001b[0m: in user code:\n\n    File \"C:\\Users\\Halim\\AppData\\Local\\Temp\\ipykernel_9684\\2754542216.py\", line 4, in None  *\n        lambda x: Dataset.from_tensors(x).repeat(6)\n\n    NameError: name 'Dataset' is not defined\n"
     ]
    }
   ],
   "source": [
    "dataset = tf.data.Dataset.range(1, 6)  # ==> [ 1, 2, 3, 4, 5 ]\n",
    "# NOTE: New lines indicate \"block\" boundaries.\n",
    "dataset = dataset.interleave(\n",
    "    lambda x: Dataset.from_tensors(x).repeat(6),\n",
    "    cycle_length=2, block_length=4)\n",
    "list(dataset.as_numpy_iterator())"
   ]
  },
  {
   "cell_type": "raw",
   "id": "01ed60ad",
   "metadata": {},
   "source": [
    "num_parallel_calls\n",
    "\n",
    "(Optional.) If specified, the implementation creates a threadpool, which is used to fetch inputs from cycle elements asynchronously and in parallel. The default behavior is to fetch inputs from cycle elements synchronously with no parallelism. If the value tf.data.AUTOTUNE is used, then the number of parallel calls is set dynamically based on available CPU. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "406a135d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset =tf.data.Dataset.range(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4b27c389",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(0, shape=(), dtype=int64)\n",
      "tf.Tensor(1, shape=(), dtype=int64)\n",
      "tf.Tensor(2, shape=(), dtype=int64)\n",
      "tf.Tensor(3, shape=(), dtype=int64)\n",
      "tf.Tensor(4, shape=(), dtype=int64)\n",
      "tf.Tensor(5, shape=(), dtype=int64)\n",
      "tf.Tensor(6, shape=(), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "for i in dataset:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "fc4a4b6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2]\n",
      "[1 2 3]\n",
      "[2 3 4]\n",
      "[3 4 5]\n",
      "[4 5 6]\n"
     ]
    }
   ],
   "source": [
    "size = 3\n",
    "dataset = tf.data.Dataset.range(7).window(size, shift=1,\n",
    "                                          drop_remainder=True)\n",
    "batched = dataset.flat_map(lambda x:x.batch(3))\n",
    "for batch in batched:\n",
    "  print(batch.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d6154c22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_VariantDataset element_spec=TensorSpec(shape=(), dtype=tf.int64, name=None)>\n",
      "<_VariantDataset element_spec=TensorSpec(shape=(), dtype=tf.int64, name=None)>\n",
      "<_VariantDataset element_spec=TensorSpec(shape=(), dtype=tf.int64, name=None)>\n",
      "<_VariantDataset element_spec=TensorSpec(shape=(), dtype=tf.int64, name=None)>\n",
      "<_VariantDataset element_spec=TensorSpec(shape=(), dtype=tf.int64, name=None)>\n",
      "[0 1 2]\n",
      "[1 2 3]\n",
      "[2 3 4]\n",
      "[3 4 5]\n",
      "[4 5 6]\n"
     ]
    }
   ],
   "source": [
    "size = 3\n",
    "dataset = tf.data.Dataset.range(7).window(size, shift=1,\n",
    "                                          drop_remainder=True)\n",
    "for i in dataset:\n",
    "    print(i)\n",
    "    \n",
    "batched = dataset.flat_map(lambda x:x.batch(3))\n",
    "for batch in batched:\n",
    "  print(batch.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f50f9202",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n",
      "[1]\n",
      "[2]\n",
      "[1]\n",
      "[2]\n",
      "[3]\n",
      "[2]\n",
      "[3]\n",
      "[4]\n",
      "[3]\n",
      "[4]\n",
      "[5]\n",
      "[4]\n",
      "[5]\n",
      "[6]\n"
     ]
    }
   ],
   "source": [
    "size = 3\n",
    "dataset = tf.data.Dataset.range(7).window(size, shift=1,\n",
    "                                          drop_remainder=True)\n",
    "batched = dataset.flat_map(lambda x:x.batch(1))\n",
    "for batch in batched:\n",
    "  print(batch.numpy())"
   ]
  },
  {
   "cell_type": "raw",
   "id": "09a724e7",
   "metadata": {},
   "source": [
    "prefetch\n",
    "prefetch(\n",
    "    buffer_size, name=None\n",
    ")\n",
    "Creates a Dataset that prefetches elements from this dataset.\n",
    "\n",
    "Most dataset input pipelines should end with a call to prefetch. This allows later elements to be prepared while the current element is being processed. This often improves latency and throughput, at the cost of using additional memory to store prefetched elements.\n",
    "\n",
    "Note: Like other Dataset methods, prefetch operates on the elements of the input dataset. It has no concept of examples vs. batches. examples.prefetch(2) will prefetch two elements (2 examples), while examples.batch(20).prefetch(2) will prefetch 2 elements (2 batches, of 20 examples each)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c0db4d11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = tf.data.Dataset.range(3)\n",
    "dataset = dataset.prefetch(2)\n",
    "list(dataset.as_numpy_iterator())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f73c08a",
   "metadata": {},
   "source": [
    "https://www.tensorflow.org/guide/data_performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf620c7",
   "metadata": {},
   "source": [
    "https://www.tensorflow.org/guide/autodiff"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "844d48ba",
   "metadata": {},
   "source": [
    "Gradient tapes\n",
    "\n",
    "TensorFlow provides the tf.GradientTape API for automatic differentiation; that is, computing the gradient of a computation with respect to some inputs, usually tf.Variables. TensorFlow \"records\" relevant operations executed inside the context of a tf.GradientTape onto a \"tape\". TensorFlow then uses that tape to compute the gradients of a \"recorded\" computation using reverse mode differentiation.\n",
    "\n",
    "Here is a simple example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a9a18ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "x = tf.Variable(3.0)\n",
    "\n",
    "with tf.GradientTape() as tape:\n",
    "  y = x**2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55ae5985",
   "metadata": {},
   "source": [
    "Once you've recorded some operations, use GradientTape.gradient(target, sources) to calculate the gradient of some target (often a loss) relative to some source (often the model's variables):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8bed7f0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dy = 2x * dx\n",
    "dy_dx = tape.gradient(y, x)\n",
    "dy_dx.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "0490e0cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "x = tf.Variable(3.0)\n",
    "q = tf.Variable(3.0)\n",
    "\n",
    "with tf.GradientTape() as tape:\n",
    "    y = x**2\n",
    "#     z = x**3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "d9f0a609",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.0"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dy = 2x * dx\n",
    "dz_dx = tape.gradient(y, x)\n",
    "dz_dx.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "ab1ed28f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# x = tf.Variable(3.0)\n",
    "q = tf.Variable(2.0)\n",
    "\n",
    "with tf.GradientTape() as tape:\n",
    "    y = x**2\n",
    "#     z = x**3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "640ff023",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[1;32mIn [94]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m dy_dx \u001b[38;5;241m=\u001b[39m tape\u001b[38;5;241m.\u001b[39mgradient(y, q)\n\u001b[1;32m----> 2\u001b[0m \u001b[43mdy_dx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m()\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'numpy'"
     ]
    }
   ],
   "source": [
    "dy_dx = tape.gradient(y, q)\n",
    "dy_dx.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e53c00",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f1525707479c6e15e791e69ce3aed8fb10ac39f50e8f20ca8228d3e8179a92a1"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
